{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMmzJXhpia-I"
      },
      "source": [
        "### APS 1052 Final Project - VOO Weekly & Monthly Returns by ElasticNet Regression Model\n",
        "\n",
        "The goal of the project is to use the stock ElasticNet model to predict the future weekly and monthly returns of an ETF. The model is using stock data provided by Yahoo Finance.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "!pip install yahoofinancials\n",
        "\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n",
        "!dpkg -i libta.deb ta.deb\n",
        "!pip install ta-lib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDoeEsjx25cb",
        "outputId": "70d3c960-f2e8-4a2f-c38e-c4a52970df92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.8/dist-packages (0.1.94)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.8/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.8/dist-packages (from yfinance) (38.0.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.8/dist-packages (from yfinance) (2.28.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.0->yfinance) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yahoofinancials in /usr/local/lib/python3.8/dist-packages (1.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from yahoofinancials) (4.6.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from yahoofinancials) (2022.6)\n",
            "(Reading database ... 124042 files and directories currently installed.)\n",
            "Preparing to unpack libta.deb ...\n",
            "Unpacking libta-lib0 (0.4.0-oneiric1) over (0.4.0-oneiric1) ...\n",
            "Preparing to unpack ta.deb ...\n",
            "Unpacking ta-lib0-dev (0.4.0-oneiric1) over (0.4.0-oneiric1) ...\n",
            "Setting up libta-lib0 (0.4.0-oneiric1) ...\n",
            "Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ta-lib in /usr/local/lib/python3.8/dist-packages (0.4.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ta-lib) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KrElML1ia-L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "from matplotlib import pyplot\n",
        "from pandas.plotting import scatter_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from scipy.stats import spearmanr\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from pickle import dump\n",
        "from pickle import load\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_regression\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from pandas.plotting import scatter_matrix\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "import fAux \n",
        "import detrendPrice\n",
        "import WhiteRealityCheckFor1\n",
        "import talib as ta\n",
        "\n",
        "# Data Source\n",
        "import yfinance as yf\n",
        "from yahoofinancials import YahooFinancials"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data from Yahoo Finance\n",
        "\n",
        "# stocks data\n",
        "tlsa_data = yf.download('TSLA', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "ge_data = yf.download('GE', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "f_data = yf.download('F', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "\n",
        "\n",
        "# ETFs data\n",
        "vug_data = yf.download('VUG', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "spy_data = yf.download('SPY', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "agg_data = yf.download('AGG', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "\n",
        "# indices data\n",
        "gspc_data = yf.download('^GSPC', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "dji_data = yf.download('^DJI', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "ixic_data = yf.download('^IXIC', start='2002-12-15', end='2022-12-15', progress=False)\n",
        "\n",
        "# Predicting ETF\n",
        "voo_data = yf.download('VOO', start='2012-02-15', end='2022-12-15', progress=False)"
      ],
      "metadata": {
        "id": "tnmCvsUsq6-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data to local\n",
        "tlsa_data.to_excel(\"tlsa_data.xlsx\")\n",
        "ge_data.to_excel(\"ge_data.xlsx\")\n",
        "f_data.to_excel(\"f_data.xlsx\")\n",
        "vug_data.to_excel(\"vug_data.xlsx\")\n",
        "spy_data.to_excel(\"spy_data.xlsx\")\n",
        "agg_data.to_excel(\"agg_data.xlsx\")\n",
        "gspc_data.to_excel(\"gspc_data.xlsx\")\n",
        "dji_data.to_excel(\"dji_data.xlsx\")\n",
        "ixic_data.to_excel(\"ixic_data.xlsx\")\n",
        "voo_data.to_excel(\"voo_data.xlsx\")"
      ],
      "metadata": {
        "id": "4LJR4TCY3SUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "def clean_data(df): \n",
        "    cleaned_df = pd.DataFrame()\n",
        "    cleaned_df[\"Date\"] = pd.to_datetime(df.iloc[:, 0])\n",
        "    cleaned_df[[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]] = df[[\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]].astype(str).astype(float)\n",
        "    return cleaned_df\n",
        " \n",
        "df_list = [tlsa_data, ge_data, f_data, vug_data, spy_data, agg_data, gspc_data, dji_data, ixic_data, voo_data]\n",
        "\n",
        "for stock in df_list: \n",
        "    df = pd.DataFrame()\n",
        "    df = clean_data(stock)\n",
        "    stock = df"
      ],
      "metadata": {
        "id": "4uSYy0iewEb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monthly Return Model"
      ],
      "metadata": {
        "id": "Vbk9IcXQy8QS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicators\n",
        "\n",
        "def calculate_indicator(df, indicator):\n",
        "    copy_df = df\n",
        "    return_period = 21\n",
        "    if 'TRIX' in indicator:\n",
        "        trix = ta.TRIX(df.Close.values)\n",
        "        copy_df['Trix'] = trix.tolist()\n",
        "    if 'DX' in indicator: \n",
        "        dx = ta.DX(df.High.values, df.Low.values, df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Dx'] = dx.tolist()\n",
        "    if 'SMA' in indicator: \n",
        "        sma = ta.SMA(df.Close.values)\n",
        "        copy_df['Sma'] = sma.tolist()\n",
        "    if 'CCI' in indicator: \n",
        "        cci = ta.CCI(df.High.values, df.Low.values, df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Cci'] = cci.tolist()\n",
        "    if 'ROC' in indicator: \n",
        "        roc = ta.ROC(df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Roc'] = roc.tolist()\n",
        "    if 'CMO' in indicator: \n",
        "        cmo = ta.CMO(df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Cmo'] = cmo.tolist()\n",
        "    if 'ATR' in indicator: \n",
        "        atr = ta.ATR(df.High.values, df.Low.values, df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Atr'] = atr.tolist()\n",
        "    return copy_df"
      ],
      "metadata": {
        "id": "pntiSHI7wjBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define monthly return period\n",
        "return_period = 21\n",
        "\n",
        "# Calculate lags from return period \n",
        "def calculate_lags(df):\n",
        "    temp = pd.DataFrame(np.log(df[\"Adj Close\"]).diff(return_period).shift(-return_period))\n",
        "    return temp\n",
        "\n",
        "appended_data = []\n",
        "for stock in df_list:\n",
        "    temp = calculate_lags(stock)\n",
        "    appended_data.append(temp)\n",
        "\n",
        "dataset = pd.DataFrame()\n",
        "dataset = pd.concat(appended_data, axis=1)\n",
        "col_names = [\"TSLA\", \"GE\", \"F\", \"VUG\", \"SPY\", \"AGG\", \"GSPC\", \"DJI\", \"IXIC\", \"VOO_Predicted\"]\n",
        "dataset.columns = col_names\n",
        "\n",
        "# calculate lags for VOO\n",
        "voo_lags = pd.concat([np.log(voo_data[\"Adj Close\"]).diff(i) for i in [return_period, return_period*3, return_period*6, return_period*10]], axis=1)\n",
        "voo_lags.columns = [\"VOO_\" + str(return_period), \"VOO_\" + str(return_period*3), \"VOO_\" + str(return_period*6), \"VOO_\" + str(return_period*10)]\n",
        "\n",
        "# Compose complete dataset\n",
        "complete_data = pd.concat([dataset, voo_lags], axis=1).dropna().iloc[::return_period, :]\n",
        "\n",
        "# Extract X and Y variables \n",
        "CopyX = complete_data[[\"VOO_Predicted\"]].copy()\n",
        "Y = complete_data[[\"VOO_Predicted\"]].reset_index(drop= True)\n",
        "X = complete_data.loc[:, complete_data.columns != 'VOO_Predicted']"
      ],
      "metadata": {
        "id": "hCkOMRpBwqpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voo = calculate_indicator(voo_data, ['TRIX','DX','CMO','ROC','CCI','ATR'])\n",
        "X = X.join(voo.iloc[:,-6:])\n",
        "X = X.fillna(X.mean())\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=0)"
      ],
      "metadata": {
        "id": "VttolAObxeE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "LH4S0TFY1uAr",
        "outputId": "3d0c9937-9d12-4409-8f18-d6f75ba278b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                TSLA        GE         F       VUG       SPY       AGG  \\\n",
              "Date                                                                     \n",
              "2012-12-17 -0.000581 -0.020064  0.221914  0.036020  0.036065 -0.000452   \n",
              "2013-01-17  0.133241  0.108876 -0.083133  0.025681  0.034858 -0.004243   \n",
              "2013-02-19 -0.088586 -0.004137  0.028085  0.018836  0.020234  0.003974   \n",
              "2013-03-20  0.285524 -0.075683 -0.032715 -0.008498 -0.001350  0.010384   \n",
              "2013-04-19  0.631490  0.080361  0.159149  0.074735  0.071058 -0.007580   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-06-22  0.142497  0.056206  0.110400  0.074960  0.053815  0.027010   \n",
              "2022-07-22  0.062886  0.092252  0.172287  0.048862  0.045181 -0.015743   \n",
              "2022-08-22  0.036864 -0.136784 -0.144581 -0.101200 -0.086916 -0.027960   \n",
              "2022-09-21 -0.372375  0.071541 -0.103234 -0.054566 -0.032259 -0.049021   \n",
              "2022-10-20 -0.140059  0.200216  0.183188  0.051154  0.080470  0.037639   \n",
              "\n",
              "                GSPC       DJI      IXIC    VOO_21    VOO_63   VOO_126  \\\n",
              "Date                                                                     \n",
              "2012-12-17  0.034751  0.026883  0.040809  0.059421 -0.017541  0.076724   \n",
              "2013-01-17  0.033205  0.031825  0.024441  0.035305  0.034092  0.094708   \n",
              "2013-02-19  0.017977  0.033355  0.012555  0.034669  0.129395  0.096271   \n",
              "2013-03-20 -0.002222  0.002463 -0.014901  0.020462  0.090436  0.072895   \n",
              "2013-04-19  0.068963  0.052736  0.086700 -0.001015  0.054116  0.088208   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-06-22  0.052266  0.045410  0.068277 -0.035596 -0.179128 -0.187765   \n",
              "2022-07-22  0.043555  0.035850  0.045223  0.054188 -0.098887 -0.115466   \n",
              "2022-08-22 -0.087863 -0.091129 -0.098494  0.044922  0.063514 -0.042223   \n",
              "2022-09-21 -0.033306  0.004951 -0.055462 -0.086921  0.012189 -0.166939   \n",
              "2022-10-20  0.078550  0.106597  0.048833 -0.032098 -0.074097 -0.172984   \n",
              "\n",
              "             VOO_210      Trix         Dx         Cci       Roc        Cmo  \\\n",
              "Date                                                                         \n",
              "2012-12-17  0.082474 -0.017518  10.242145  103.858411  6.122125  15.040286   \n",
              "2013-01-17  0.072057  0.037185  24.748683  115.473650  2.854102  25.224797   \n",
              "2013-02-19  0.114924  0.107589  37.545174  146.643558  3.527674  36.736292   \n",
              "2013-03-20  0.181704  0.120068  17.961823   83.485529  2.067290  28.338905   \n",
              "2013-04-19  0.166146  0.106198  15.212593  -78.590905 -0.572700   3.079638   \n",
              "...              ...       ...        ...         ...       ...        ...   \n",
              "2022-06-22 -0.155023 -0.189012  25.885263  -85.453498 -3.497008 -21.227919   \n",
              "2022-07-22 -0.082089 -0.183844   1.414520  143.559942  5.137482   3.580161   \n",
              "2022-08-22 -0.079538  0.029844   8.418863    0.180444  4.594632   6.544331   \n",
              "2022-09-21 -0.203899  0.014571  19.768281 -128.229949 -8.325000 -23.187680   \n",
              "2022-10-20 -0.207674 -0.160995  24.909820   12.810704 -3.583018 -12.773532   \n",
              "\n",
              "                 Atr  \n",
              "Date                  \n",
              "2012-12-17  1.311239  \n",
              "2013-01-17  1.238994  \n",
              "2013-02-19  1.054138  \n",
              "2013-03-20  1.174234  \n",
              "2013-04-19  1.481175  \n",
              "...              ...  \n",
              "2022-06-22  9.035205  \n",
              "2022-07-22  7.584105  \n",
              "2022-08-22  6.268675  \n",
              "2022-09-21  6.913978  \n",
              "2022-10-20  7.950217  \n",
              "\n",
              "[119 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6cc54f2-cbe3-422f-a109-7b88a2b4aaeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TSLA</th>\n",
              "      <th>GE</th>\n",
              "      <th>F</th>\n",
              "      <th>VUG</th>\n",
              "      <th>SPY</th>\n",
              "      <th>AGG</th>\n",
              "      <th>GSPC</th>\n",
              "      <th>DJI</th>\n",
              "      <th>IXIC</th>\n",
              "      <th>VOO_21</th>\n",
              "      <th>VOO_63</th>\n",
              "      <th>VOO_126</th>\n",
              "      <th>VOO_210</th>\n",
              "      <th>Trix</th>\n",
              "      <th>Dx</th>\n",
              "      <th>Cci</th>\n",
              "      <th>Roc</th>\n",
              "      <th>Cmo</th>\n",
              "      <th>Atr</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2012-12-17</th>\n",
              "      <td>-0.000581</td>\n",
              "      <td>-0.020064</td>\n",
              "      <td>0.221914</td>\n",
              "      <td>0.036020</td>\n",
              "      <td>0.036065</td>\n",
              "      <td>-0.000452</td>\n",
              "      <td>0.034751</td>\n",
              "      <td>0.026883</td>\n",
              "      <td>0.040809</td>\n",
              "      <td>0.059421</td>\n",
              "      <td>-0.017541</td>\n",
              "      <td>0.076724</td>\n",
              "      <td>0.082474</td>\n",
              "      <td>-0.017518</td>\n",
              "      <td>10.242145</td>\n",
              "      <td>103.858411</td>\n",
              "      <td>6.122125</td>\n",
              "      <td>15.040286</td>\n",
              "      <td>1.311239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-17</th>\n",
              "      <td>0.133241</td>\n",
              "      <td>0.108876</td>\n",
              "      <td>-0.083133</td>\n",
              "      <td>0.025681</td>\n",
              "      <td>0.034858</td>\n",
              "      <td>-0.004243</td>\n",
              "      <td>0.033205</td>\n",
              "      <td>0.031825</td>\n",
              "      <td>0.024441</td>\n",
              "      <td>0.035305</td>\n",
              "      <td>0.034092</td>\n",
              "      <td>0.094708</td>\n",
              "      <td>0.072057</td>\n",
              "      <td>0.037185</td>\n",
              "      <td>24.748683</td>\n",
              "      <td>115.473650</td>\n",
              "      <td>2.854102</td>\n",
              "      <td>25.224797</td>\n",
              "      <td>1.238994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-02-19</th>\n",
              "      <td>-0.088586</td>\n",
              "      <td>-0.004137</td>\n",
              "      <td>0.028085</td>\n",
              "      <td>0.018836</td>\n",
              "      <td>0.020234</td>\n",
              "      <td>0.003974</td>\n",
              "      <td>0.017977</td>\n",
              "      <td>0.033355</td>\n",
              "      <td>0.012555</td>\n",
              "      <td>0.034669</td>\n",
              "      <td>0.129395</td>\n",
              "      <td>0.096271</td>\n",
              "      <td>0.114924</td>\n",
              "      <td>0.107589</td>\n",
              "      <td>37.545174</td>\n",
              "      <td>146.643558</td>\n",
              "      <td>3.527674</td>\n",
              "      <td>36.736292</td>\n",
              "      <td>1.054138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-03-20</th>\n",
              "      <td>0.285524</td>\n",
              "      <td>-0.075683</td>\n",
              "      <td>-0.032715</td>\n",
              "      <td>-0.008498</td>\n",
              "      <td>-0.001350</td>\n",
              "      <td>0.010384</td>\n",
              "      <td>-0.002222</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>-0.014901</td>\n",
              "      <td>0.020462</td>\n",
              "      <td>0.090436</td>\n",
              "      <td>0.072895</td>\n",
              "      <td>0.181704</td>\n",
              "      <td>0.120068</td>\n",
              "      <td>17.961823</td>\n",
              "      <td>83.485529</td>\n",
              "      <td>2.067290</td>\n",
              "      <td>28.338905</td>\n",
              "      <td>1.174234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-19</th>\n",
              "      <td>0.631490</td>\n",
              "      <td>0.080361</td>\n",
              "      <td>0.159149</td>\n",
              "      <td>0.074735</td>\n",
              "      <td>0.071058</td>\n",
              "      <td>-0.007580</td>\n",
              "      <td>0.068963</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>0.086700</td>\n",
              "      <td>-0.001015</td>\n",
              "      <td>0.054116</td>\n",
              "      <td>0.088208</td>\n",
              "      <td>0.166146</td>\n",
              "      <td>0.106198</td>\n",
              "      <td>15.212593</td>\n",
              "      <td>-78.590905</td>\n",
              "      <td>-0.572700</td>\n",
              "      <td>3.079638</td>\n",
              "      <td>1.481175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-22</th>\n",
              "      <td>0.142497</td>\n",
              "      <td>0.056206</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.074960</td>\n",
              "      <td>0.053815</td>\n",
              "      <td>0.027010</td>\n",
              "      <td>0.052266</td>\n",
              "      <td>0.045410</td>\n",
              "      <td>0.068277</td>\n",
              "      <td>-0.035596</td>\n",
              "      <td>-0.179128</td>\n",
              "      <td>-0.187765</td>\n",
              "      <td>-0.155023</td>\n",
              "      <td>-0.189012</td>\n",
              "      <td>25.885263</td>\n",
              "      <td>-85.453498</td>\n",
              "      <td>-3.497008</td>\n",
              "      <td>-21.227919</td>\n",
              "      <td>9.035205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-22</th>\n",
              "      <td>0.062886</td>\n",
              "      <td>0.092252</td>\n",
              "      <td>0.172287</td>\n",
              "      <td>0.048862</td>\n",
              "      <td>0.045181</td>\n",
              "      <td>-0.015743</td>\n",
              "      <td>0.043555</td>\n",
              "      <td>0.035850</td>\n",
              "      <td>0.045223</td>\n",
              "      <td>0.054188</td>\n",
              "      <td>-0.098887</td>\n",
              "      <td>-0.115466</td>\n",
              "      <td>-0.082089</td>\n",
              "      <td>-0.183844</td>\n",
              "      <td>1.414520</td>\n",
              "      <td>143.559942</td>\n",
              "      <td>5.137482</td>\n",
              "      <td>3.580161</td>\n",
              "      <td>7.584105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-22</th>\n",
              "      <td>0.036864</td>\n",
              "      <td>-0.136784</td>\n",
              "      <td>-0.144581</td>\n",
              "      <td>-0.101200</td>\n",
              "      <td>-0.086916</td>\n",
              "      <td>-0.027960</td>\n",
              "      <td>-0.087863</td>\n",
              "      <td>-0.091129</td>\n",
              "      <td>-0.098494</td>\n",
              "      <td>0.044922</td>\n",
              "      <td>0.063514</td>\n",
              "      <td>-0.042223</td>\n",
              "      <td>-0.079538</td>\n",
              "      <td>0.029844</td>\n",
              "      <td>8.418863</td>\n",
              "      <td>0.180444</td>\n",
              "      <td>4.594632</td>\n",
              "      <td>6.544331</td>\n",
              "      <td>6.268675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-21</th>\n",
              "      <td>-0.372375</td>\n",
              "      <td>0.071541</td>\n",
              "      <td>-0.103234</td>\n",
              "      <td>-0.054566</td>\n",
              "      <td>-0.032259</td>\n",
              "      <td>-0.049021</td>\n",
              "      <td>-0.033306</td>\n",
              "      <td>0.004951</td>\n",
              "      <td>-0.055462</td>\n",
              "      <td>-0.086921</td>\n",
              "      <td>0.012189</td>\n",
              "      <td>-0.166939</td>\n",
              "      <td>-0.203899</td>\n",
              "      <td>0.014571</td>\n",
              "      <td>19.768281</td>\n",
              "      <td>-128.229949</td>\n",
              "      <td>-8.325000</td>\n",
              "      <td>-23.187680</td>\n",
              "      <td>6.913978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-20</th>\n",
              "      <td>-0.140059</td>\n",
              "      <td>0.200216</td>\n",
              "      <td>0.183188</td>\n",
              "      <td>0.051154</td>\n",
              "      <td>0.080470</td>\n",
              "      <td>0.037639</td>\n",
              "      <td>0.078550</td>\n",
              "      <td>0.106597</td>\n",
              "      <td>0.048833</td>\n",
              "      <td>-0.032098</td>\n",
              "      <td>-0.074097</td>\n",
              "      <td>-0.172984</td>\n",
              "      <td>-0.207674</td>\n",
              "      <td>-0.160995</td>\n",
              "      <td>24.909820</td>\n",
              "      <td>12.810704</td>\n",
              "      <td>-3.583018</td>\n",
              "      <td>-12.773532</td>\n",
              "      <td>7.950217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>119 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6cc54f2-cbe3-422f-a109-7b88a2b4aaeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6cc54f2-cbe3-422f-a109-7b88a2b4aaeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6cc54f2-cbe3-422f-a109-7b88a2b4aaeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "std_slc = StandardScaler()\n",
        "pca = PCA()\n",
        "elasticnet = ElasticNet()\n",
        "\n",
        "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
        "                           ('pca', pca),\n",
        "                           ('elasticnet', elasticnet)])\n",
        "\n",
        "\n",
        "n_components = list(range(1,X.shape[1]+1,1))\n",
        "normalize = [True, False]\n",
        "selection = ['cyclic', 'random']\n",
        "l1_ratios = [0.1, 0.2, 0.5]\n",
        "parameters = dict(pca__n_components=n_components,\n",
        "                      elasticnet__normalize=normalize,\n",
        "                      elasticnet__selection=selection)"
      ],
      "metadata": {
        "id": "izeh5PgW-yT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vM_wSD73BlZH",
        "outputId": "c8153b52-b961-4593-ee76-b6c4843a4890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pca__n_components': [1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19],\n",
              " 'elasticnet__normalize': [True, False],\n",
              " 'elasticnet__selection': ['cyclic', 'random']}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_EN = GridSearchCV(pipe, parameters)\n",
        "clf_EN.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eucmlaCbAd0K",
        "outputId": "5fe650d6-cd34-4a54-b066-a3559a5e96cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('std_slc', StandardScaler()),\n",
              "                                       ('pca', PCA()),\n",
              "                                       ('elasticnet', ElasticNet())]),\n",
              "             param_grid={'elasticnet__normalize': [True, False],\n",
              "                         'elasticnet__selection': ['cyclic', 'random'],\n",
              "                         'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
              "                                               11, 12, 13, 14, 15, 16, 17, 18,\n",
              "                                               19]})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Number Of Components:', clf_EN.best_estimator_.get_params()['pca__n_components'])\n",
        "print(clf_EN.best_estimator_.get_params()['elasticnet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGY-dcMeAiID",
        "outputId": "93bc32f9-d7a8-44be-d041-27f932969701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Number Of Components: 1\n",
            "ElasticNet(normalize=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parametersGrid = {\"max_iter\": [1, 5, 10],\n",
        "                      \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                      \"l1_ratio\": np.arange(0.0, 1.0, 0.1)}"
      ],
      "metadata": {
        "id": "iTrTbytjCVPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = GridSearchCV(elasticnet, parametersGrid, scoring='r2', cv=10)\n",
        "\n",
        "grid.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ36vwIACeZA",
        "outputId": "7d5f8813-6ba7-4316-bbc2-52254d723023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.081e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.465e-03, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e-03, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e-03, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e-03, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.289e-03, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e-03, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.488e-03, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e-03, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e-03, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.712e-03, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.517e-03, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e-03, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e-03, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e-03, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.767e-03, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.160e-03, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.631e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.139e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.903e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.124e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.176e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.977e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.935e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.051e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.825e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.803e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.131e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.567e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.982e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.427e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.347e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.470e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.553e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.393e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.239e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.622e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.624e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.226e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.289e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.214e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.824e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.725e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.854e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.274e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.945e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.740e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.594e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.947e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.816e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.846e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.265e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.164e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.060e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.020e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.327e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.253e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.168e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.057e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.191e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.563e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.919e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.010e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.262e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.034e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.188e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.192e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.032e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.230e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.188e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.079e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.143e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.057e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.364e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.309e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.461e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.344e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.481e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.944e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.188e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.547e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.275e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.411e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.168e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.444e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.486e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.384e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.326e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.351e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.456e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.449e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.974e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.463e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.240e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.243e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.319e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.701e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.720e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.416e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.527e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.769e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.536e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.489e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.825e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.839e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.860e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.788e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.759e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.860e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.387e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.889e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.202e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.955e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.909e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.011e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.713e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.742e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.830e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.889e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.179e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.882e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.239e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.255e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.271e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.148e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.174e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.221e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.257e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.793e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.308e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.158e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.388e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.382e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.400e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.311e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.286e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.366e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.083e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.113e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.176e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.297e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.246e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.557e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.268e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.653e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.667e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.677e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.571e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.559e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.587e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.625e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.631e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.191e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.723e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.234e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.420e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.405e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.681e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.726e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.444e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.524e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.677e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.925e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.641e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.073e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.079e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.953e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.966e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.991e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.012e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.579e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.130e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.265e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.125e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.048e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.043e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.265e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.052e-03, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.172e-03, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.118e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.740e-03, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.778e-03, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.933e-03, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.236e-03, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.047e-03, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.792e-03, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.015e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e-03, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.027e-03, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.991e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e-03, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.933e-03, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.935e-03, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.005e-03, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.011e-03, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.545e-03, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e-03, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.590e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.542e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.512e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.773e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.937e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.786e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.553e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.580e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.616e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.925e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.707e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.534e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.891e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.065e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.121e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.030e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.768e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.932e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.928e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.065e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.921e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.266e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.129e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.738e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.739e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.772e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.843e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.720e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.225e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.089e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.153e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.146e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.061e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.807e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.815e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.043e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.901e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.543e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.624e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.497e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.471e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.552e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.176e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.162e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.027e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.001e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.008e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.164e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.221e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.068e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.241e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.867e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.866e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.914e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.634e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.948e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.833e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.799e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.790e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.765e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.874e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.317e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.443e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.356e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.160e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.177e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.190e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.342e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.383e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.210e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.429e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.232e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.191e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.197e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.091e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.241e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.156e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.788e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.345e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.501e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.522e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.597e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.468e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.445e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.405e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.374e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.376e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.318e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.503e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.382e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.419e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.371e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.300e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.952e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.753e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.672e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.491e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.470e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.476e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.642e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.741e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.731e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.630e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.577e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.676e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.167e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.736e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.552e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.592e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.094e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.789e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.801e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.617e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.587e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.589e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.764e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.738e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.868e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.876e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.839e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.874e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.685e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.292e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.859e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.875e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.904e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.989e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.912e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.691e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.870e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.822e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.635e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.981e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.062e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.030e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.920e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.905e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.055e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.041e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.963e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.940e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.065e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.700e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.625e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.441e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.677e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.688e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.673e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.697e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.635e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.639e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.304e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.690e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.570e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.560e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.634e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.252e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.331e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.264e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.141e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.008e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.978e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.264e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.153e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.342e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.602e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.686e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.599e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.568e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.230e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.730e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.431e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.552e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.463e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.439e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.371e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.159e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.438e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.606e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.782e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.924e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.886e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.761e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.425e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.397e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.905e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.534e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.086e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.955e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.214e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.360e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.297e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.225e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.700e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.220e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.441e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.869e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.096e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.030e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.991e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.369e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.061e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.884e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.667e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.202e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.062e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.275e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.277e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.124e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.648e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.577e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.292e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.847e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.110e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.312e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.408e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.635e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.606e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.523e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.833e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.482e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.128e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.785e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.732e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.877e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.237e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.196e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.842e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.996e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.846e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.466e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.383e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.190e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.491e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.502e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.370e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.740e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.637e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.525e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.019e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.521e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.774e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.757e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.679e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.816e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.555e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.233e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.868e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.736e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.256e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.219e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.236e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.204e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.669e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.012e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.867e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.366e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.414e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.175e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.570e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.586e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.470e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.724e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.627e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.617e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.037e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.111e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.590e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.400e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.775e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.763e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.683e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.800e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.526e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.589e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.217e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.753e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.863e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.603e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.141e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.103e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.140e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.850e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.772e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.310e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.189e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.565e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.584e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.468e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.651e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.605e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.006e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.110e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.582e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.378e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.756e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.745e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.667e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.788e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.505e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.564e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.203e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.726e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.846e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.483e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.038e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.998e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.050e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.003e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.440e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.734e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.692e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.217e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.575e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.594e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.474e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.768e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.672e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.615e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.015e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.108e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.586e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.357e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.741e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.729e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.779e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.489e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.547e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.194e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.831e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.376e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.945e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.903e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.970e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.621e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.212e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.584e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.602e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.479e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.788e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.693e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.624e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.023e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.101e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.588e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.338e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.726e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.714e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.641e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.771e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.477e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.643e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.816e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.281e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.817e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.896e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.851e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.557e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.552e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.053e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.221e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.591e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.609e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.482e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.806e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.712e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.631e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.032e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.587e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.711e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.700e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.629e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.765e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.468e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.165e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.586e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.801e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.195e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.780e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.738e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.826e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.789e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.481e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.696e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.978e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.131e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.309e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.279e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.176e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.790e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.737e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.301e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.029e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.337e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.699e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.859e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.818e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.733e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.173e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.908e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.680e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.831e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.792e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.693e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.251e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.166e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.733e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.360e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.875e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.230e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.597e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.615e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.483e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.826e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.732e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.638e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.042e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.585e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.702e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.691e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.618e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.775e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.486e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.512e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.149e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.790e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.120e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.705e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.664e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.755e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.749e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.418e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.395e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.909e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.191e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.545e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.563e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.428e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.902e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.819e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.598e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.113e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.936e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.484e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.197e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.543e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.574e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.460e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.731e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.455e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.462e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.974e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.245e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.629e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.683e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.368e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.438e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.305e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.112e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.063e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.443e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.460e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.340e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.803e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.728e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.507e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.111e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.734e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.345e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.835e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.206e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.247e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.182e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.641e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.423e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.132e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.785e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.805e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.240e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.964e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.923e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.021e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.222e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.592e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.892e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.295e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.311e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.211e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.681e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.611e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.045e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.148e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.392e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.861e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.849e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.059e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.755e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.554e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.348e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.810e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.434e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.509e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.189e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.493e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.917e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.655e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.090e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.109e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.037e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.510e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.445e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.187e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.892e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.149e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.877e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.360e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.416e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.324e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.290e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.220e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.230e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.738e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.896e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.481e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.869e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.066e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.236e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.816e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.841e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.806e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.279e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.219e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.937e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.659e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.514e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.856e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.914e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.020e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.975e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.516e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.272e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.121e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.791e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.887e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.769e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.959e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.315e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.374e-04, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.801e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.900e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.454e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.490e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.507e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.973e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.919e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.609e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.408e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e-02, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.028e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.307e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.363e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.872e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.732e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.076e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.686e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.409e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.457e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.737e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.209e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.732e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e-04, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.319e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.979e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.033e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.124e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.571e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.522e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.178e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.647e-03, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.376e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.264e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.728e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.938e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.827e-04, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.836e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.181e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.918e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.188e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.673e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.855e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e-05, tolerance: 6.660e-06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.287e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.438e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.635e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.060e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.616e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.624e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.305e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.970e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.629e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.089e-04, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.731e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.729e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.133e-04, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.418e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.275e-04, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.991e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.340e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.354e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.248e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.543e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.451e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.373e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.852e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.380e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.792e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.782e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.653e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.943e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.819e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.656e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.223e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.858e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.478e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.747e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.741e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.593e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.918e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.805e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.619e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.123e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.806e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.683e-02, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.527e-02, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.738e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e-02, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e-02, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.334e-02, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.866e-02, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.044e-02, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.419e-02, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e-03, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.225e-03, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.326e-03, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.397e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.422e-03, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e-03, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.445e-03, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.056e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.500e-04, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.467e-04, tolerance: 1.268e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.481e-04, tolerance: 1.270e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e-03, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.182e-04, tolerance: 1.127e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e-04, tolerance: 1.107e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.879e-04, tolerance: 1.275e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e-03, tolerance: 1.264e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.333e-05, tolerance: 1.228e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.375e-05, tolerance: 1.250e-05\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.253e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.627e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.633e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.495e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.858e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.771e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.159e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.165e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.815e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.104e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.097e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.914e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.327e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.233e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.001e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.585e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.159e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.776e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.054e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.049e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.855e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.285e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.202e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.954e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.498e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.983e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.101e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.547e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.888e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.872e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.720e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.131e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.914e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.634e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.239e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.862e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.331e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.610e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.428e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.867e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.803e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.618e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.327e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.172e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.633e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.328e-02, tolerance: 1.228e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.625e-02, tolerance: 1.268e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.606e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.424e-02, tolerance: 1.250e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.864e-02, tolerance: 1.127e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.801e-02, tolerance: 1.107e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.616e-02, tolerance: 1.275e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.322e-02, tolerance: 1.264e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.172e-02, tolerance: 6.660e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.629e-02, tolerance: 1.270e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e-03, tolerance: 1.304e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=ElasticNet(),\n",
              "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
              "                         'l1_ratio': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
              "                         'max_iter': [1, 5, 10]},\n",
              "             scoring='r2')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoInfgQ4Cm96",
        "outputId": "a8f475fc-e149-4b67-f7a2-13fb3bbbc14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=0.0001, l1_ratio=0.0, max_iter=10)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_EN.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJDb6TFrAtaf",
        "outputId": "75a53a8b-24d6-4999-8b1b-cf26802c7bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('std_slc', StandardScaler()), ('pca', PCA(n_components=1)),\n",
              "                ('elasticnet', ElasticNet(normalize=True))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "X_train = scaler.transform(x_train)\n",
        "X_test = scaler.transform(x_test)\n",
        "\n",
        "pca = PCA(n_components=1)\n",
        "pca.fit(x_train)\n",
        "X_train = pca.transform(x_train)\n",
        "X_test = pca.transform(x_test)\n",
        "\n",
        "\n",
        "best_enet = ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=True, l1_ratio=0.0,\n",
        "      max_iter=10, normalize=True, positive=False, precompute=False,\n",
        "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
        "best_enet.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcfEjdInDfZW",
        "outputId": "661e256e-92d7-4669-f86a-2e76120984a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.422e-04, tolerance: 1.304e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=0.0001, l1_ratio=0.0, max_iter=10, normalize=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_y = y_test.values.ravel()\n",
        "pred_y = best_enet.predict(x_test)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(true_y, label='true_y')\n",
        "pyplot.plot(pred_y, label='pred_y')\n",
        "pyplot.figsize=(10,20)\n",
        "pyplot.xlabel('Time')\n",
        "pyplot.ylabel('Return Range')\n",
        "pyplot.title('Train VS Test')\n",
        "pyplot.grid()\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "GTCCUWsKDtq9",
        "outputId": "0351ddde-6b76-465a-fe12-a20cb60b58f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ret = voo_data.iloc[:]['Adj Close'].pct_change(periods=1).fillna(0)\n",
        "df_ret1 = df_ret.reset_index(drop= True)[:x_train.shape[0],]\n",
        "df_ret2 = df_ret.reset_index(drop= True)[:x_test.shape[0],]"
      ],
      "metadata": {
        "id": "j7_y_xoC45sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positions = np.where(best_enet.predict(x_train)> 0,1,-1 ) \n",
        "montly_Ret = pd.Series(positions).shift(1).fillna(0).values * df_ret1\n",
        "montly_Ret = montly_Ret.fillna(0)\n",
        "cumret = np.array(np.cumprod(montly_Ret + 1) - 1)\n",
        "\n",
        "rho, pval = spearmanr(y_test,best_enet.predict(x_test)) \n",
        "cagr = (1 + cumret[-1]) ** ((253/21) / len(cumret)) - 1\n",
        "maxDD, maxDDD = fAux.calculateMaxDD(cumret)\n",
        "ratio = ((253/21) ** (1.0/2.0)) * np.mean(montly_Ret) / np.std(montly_Ret)\n",
        "print (('In-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6} Rho={:0.6} PVal={:0.6}\\n'\\\n",
        "    ).format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD, rho, pval))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFsUdmAK5Tli",
        "outputId": "824370b0-17ce-4030-f05a-3aa6d49a1054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-sample: CAGR=0.00606517 Sharpe ratio=0.241381 maxDD=-0.0535273 maxDDD=25 Calmar ratio=0.11331 Rho=0.958933 PVal=1.97601e-33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojq8iWSbMCs7",
        "outputId": "1bcafd11-cd41-4a81-efec-48b3450becd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1,  1, -1,  1, -1,  1,  1,  1,  1, -1, -1, -1, -1,  1,  1, -1,\n",
              "        1, -1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1,  1,  1, -1,  1,\n",
              "        1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1,\n",
              "        1, -1,  1,  1,  1,  1,  1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positions2 = np.where(best_enet.predict(x_test)> 0,1,-1 )\n",
        "monthly_ret2 = pd.Series(positions2).shift(1).fillna(0).values * df_ret2\n",
        "monthly_ret2 = monthly_ret2.fillna(0)\n",
        "cumret2 = np.array(np.cumprod(monthly_ret2 + 1) - 1)\n",
        "\n",
        "rho, pval = spearmanr(y_test,best_enet.predict(x_test)) \n",
        "\n",
        "cagr = (1 + cumret2[-1]) ** ((253/21) / len(cumret2)) - 1\n",
        "maxDD, maxDDD = fAux.calculateMaxDD(cumret2)\n",
        "ratio = ((253/21) ** (1.0/2.0)) * np.mean(monthly_ret2) / np.std(monthly_ret2)\n",
        "print (('Out-of-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6}  Rho={:0.6} PVal={:0.6}\\n'\\\n",
        ").format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD, rho, pval))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIpsQ7o_5W9i",
        "outputId": "4ef1f468-d8d8-4832-abc7-9a1b57fed732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-sample: CAGR=-0.0104927 Sharpe ratio=-0.389251 maxDD=-0.0858513 maxDDD=40 Calmar ratio=-0.12222  Rho=0.958933 PVal=1.97601e-33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_close=voo_data.iloc[:]['Adj Close'].reset_index(drop= True)[(x_train.shape[0]):,]\n",
        "detrended_close = detrendPrice.detrendPrice(new_close)\n",
        "detrended_ret1 = detrended_close.pct_change(periods=1).fillna(0)\n",
        "detrended_syst_rets = detrended_ret1 * pd.Series(positions2).shift(1).fillna(0)\n",
        "WhiteRealityCheckFor1.bootstrap(detrended_syst_rets)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "cROMMWhp5q4r",
        "outputId": "1520ea19-4725-468b-d514-3b0b74f97713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average return -0.001469\n",
            "[-0.00194573  0.00205168]\n",
            "Do not reject Ho = The population distribution of rule returns has an expected value of zero or less (because p_value is not small enough)\n",
            "p_value:\n",
            "0.9292\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWX0lEQVR4nO3dfYxcV3nH8e+PJCQuC3beOnVtqw7FbRWyIpBRCII/ZpNSTIJwkIAGuWBD2qVqUEGYNg78QQtFNVA3hUJDF0JxSmAJgShWSEqDYRQh1YQYQjYvpDHJpnhl7ALGsJAGbXj6xxyH8Wa9cz0zd17O/j7SaO8995w75z6efXz23Dv3KiIwM7O8PK3fHTAzs+5zcjczy5CTu5lZhpzczcwy5ORuZpahE/vdAYAzzjgj1q5d21bbn//85zzjGc/obocy5DgV4zgV4zgVU3ac9uzZ88OIOHOhbQOR3NeuXctdd93VVtt6vU6tVutuhzLkOBXjOBXjOBVTdpwkPXqsbZ6WMTPLkJO7mVmGnNzNzDLk5G5mliEndzOzDDm5m5llyMndzCxDTu5mZhlycjczy9BAfEPVrExrt35p0e3T2y7pUU/MescjdzOzDDm5m5llqHByl3SCpG9LuiWtnyXpG5L2SvqcpKen8pPT+t60fW05XTczs2M5npH7W4EHmtbfD1wdEc8BDgGXp/LLgUOp/OpUz8zMeqhQcpe0GrgE+ERaF3AhcGOqsgO4NC1vSOuk7Rel+mZm1iOKiNaVpBuBvweeCbwD2AzsTqNzJK0BbouIcyTdC6yPiH1p2/eAF0bED+ftcxwYB6hUKudNTk62dQCzs7OMjIy01XYpWcpxmpo5vOj20VXLn1xeynE6Ho5TMWXHaWxsbE9EVBfa1vJSSEmvAA5GxB5JtW51KiImgAmAarUa7d7Q3g8NKGYpx2lzq0shN9aeXF7KcToejlMx/YxTkevcXwy8UtLFwCnAs4APASsknRgRc8BqYCbVnwHWAPsknQgsB37U9Z6bmdkxtUzuEXEVcBVAGrm/IyI2Svo88GpgEtgE3Jya7Ezr/5W2fzWKzP2YDajFvgTlL0DZoOrkOvcrgbdL2gucDlybyq8FTk/lbwe2dtZFMzM7Xsd1+4GIqAP1tPwwcP4Cdf4PeE0X+mZmZm3yN1TNzDLk5G5mliHfFdKWvOYTpltG51peOmk2DDxyNzPLkJO7mVmGnNzNzDLkOXfLQqunLZktNR65m5llyMndzCxDTu5mZhlycjczy5CTu5lZhpzczcwy5ORuZpYhJ3czswz5S0xmHWj15Sk/qcn6peXIXdIpku6U9B1J90n621T+KUmPSLo7vc5N5ZL0YUl7Jd0j6QVlH4SZmR2tyMj9ceDCiJiVdBLwdUm3pW1/FRE3zqv/cmBder0QuCb9NDOzHmk5co+G2bR6Unot9sDrDcB1qd1uYIWklZ131czMilLEYnk6VZJOAPYAzwE+GhFXSvoU8CIaI/tdwNaIeFzSLcC2iPh6arsLuDIi7pq3z3FgHKBSqZw3OTnZ1gHMzs4yMjLSVtulJPc4Tc0c7sp+KsvgwGNd2RUAo6uWd29nAyT3z1O3lB2nsbGxPRFRXWhboROqEfEEcK6kFcBNks4BrgJ+ADwdmACuBN5TtFMRMZHaUa1Wo1arFW16lHq9Trttl5Lc49StpydtGZ1j+1T3rjOY3ljr2r4GSe6fp27pZ5yO61LIiPgJ8DVgfUTsT1MvjwP/Bpyfqs0Aa5qarU5lZmbWI0WuljkzjdiRtAx4KfDdI/PokgRcCtybmuwE3pCumrkAOBwR+0vpvZmZLajI358rgR1p3v1pwA0RcYukr0o6ExBwN/Dnqf6twMXAXuAXwBu7320zM1tMy+QeEfcAz1+g/MJj1A/gis67ZmZm7fLtB8zMMuTkbmaWISd3M7MMObmbmWXIyd3MLEO+5a8NhVa31jWzozm5m/WJ7wVvZfK0jJlZhpzczcwy5ORuZpYhz7mblcgngq1fPHI3M8uQk7uZWYac3M3MMuTkbmaWISd3M7MMtbxaRtIpwB3Ayan+jRHxbklnAZPA6cAe4PUR8UtJJwPXAecBPwL+OCKmS+q/ZcRXlph1T5GR++PAhRHxPOBcYH16Nur7gasj4jnAIeDyVP9y4FAqvzrVMzOzHmqZ3KNhNq2elF4BXAjcmMp30HhINsCGtE7aflF6iLaZmfWIGo88bVGp8XDsPcBzgI8CHwR2p9E5ktYAt0XEOZLuBdZHxL607XvACyPih/P2OQ6MA1QqlfMmJyfbOoDZ2VlGRkbaaruUDEOcpmYO97sLVJbBgcf63YuG0VXL+92FYxqGz9MgKDtOY2NjeyKiutC2Qt9QjYgngHMlrQBuAv6g005FxAQwAVCtVqNWq7W1n3q9Trttl5JhiNPmAZhz3zI6x/apwfji9vTGWr+7cEzD8HkaBP2M03FdLRMRPwG+BrwIWCHpyG/BamAmLc8AawDS9uU0TqyamVmPtEzuks5MI3YkLQNeCjxAI8m/OlXbBNyclnemddL2r0aRuR8zM+uaIn9/rgR2pHn3pwE3RMQtku4HJiX9HfBt4NpU/1rg3yXtBX4MXFZCv83MbBEtk3tE3AM8f4Hyh4HzFyj/P+A1XemdmZm1xd9QNTPLkJO7mVmGnNzNzDLk5G5mliEndzOzDDm5m5llyMndzCxDTu5mZhlycjczy5CTu5lZhpzczcwy5ORuZpYhJ3czsww5uZuZZcjJ3cwsQ07uZmYZavmwDklrgOuAChDARER8SNLfAH8G/G+q+s6IuDW1uQq4HHgC+MuI+HIJfTfL2toWDwyf3nZJj3piw6jIY/bmgC0R8S1JzwT2SLo9bbs6Iv6hubKks2k8Wu+5wG8DX5H0exHxRDc7bmZmx9ZyWiYi9kfEt9Lyz2g8HHvVIk02AJMR8XhEPALsZYHH8ZmZWXkUEcUrS2uBO4BzgLcDm4GfAnfRGN0fkvQRYHdEfDq1uRa4LSJunLevcWAcoFKpnDc5OdnWAczOzjIyMtJW26VkGOI0NXO4312gsgwOPNbvXhQzump53957GD5Pg6DsOI2Nje2JiOpC24pMywAgaQT4AvC2iPippGuA99KYh38vsB14U9H9RcQEMAFQrVajVqsVbXqUer1Ou22XkmGI0+YWc8y9sGV0ju1ThX8t+mp6Y61v7z0Mn6dB0M84FbpaRtJJNBL79RHxRYCIOBART0TEr4CP8+uplxlgTVPz1anMzMx6pGVylyTgWuCBiPjHpvKVTdVeBdyblncCl0k6WdJZwDrgzu512czMWiny9+eLgdcDU5LuTmXvBF4n6Vwa0zLTwJsBIuI+STcA99O40uYKXylj0PrSPjPrnpbJPSK+DmiBTbcu0uZ9wPs66JeZmXXA31A1M8uQk7uZWYac3M3MMuTkbmaWISd3M7MMObmbmWXIyd3MLENO7mZmGXJyNzPLkJO7mVmGnNzNzDLk5G5mliEndzOzDDm5m5llyMndzCxDTu5mZhkq8pi9NZK+Jul+SfdJemsqP03S7ZIeSj9PTeWS9GFJeyXdI+kFZR+EmZkdrcjIfQ7YEhFnAxcAV0g6G9gK7IqIdcCutA7wchrPTV0HjAPXdL3XZma2qCKP2dsP7E/LP5P0ALAK2ADUUrUdQB24MpVfFxEB7Ja0QtLKtB8z65LFnkk7ve2SHvbEBpEaObhgZWktcAdwDvA/EbEilQs4FBErJN0CbEvPXkXSLuDKiLhr3r7GaYzsqVQq501OTrZ1ALOzs4yMjLTVdikZhDhNzRzu6/sXUVkGBx7rdy86N7pqean7H4TP0zAoO05jY2N7IqK60LaWI/cjJI0AXwDeFhE/beTzhogIScX/l2i0mQAmAKrVatRqteNp/qR6vU67bZeSQYjT5kVGmoNiy+gc26cK/1oMrOmNtVL3Pwifp2HQzzgVulpG0kk0Evv1EfHFVHxA0sq0fSVwMJXPAGuamq9OZWZm1iNFrpYRcC3wQET8Y9OmncCmtLwJuLmp/A3pqpkLgMOebzcz660if3++GHg9MCXp7lT2TmAbcIOky4FHgdembbcCFwN7gV8Ab+xqj83MrKUiV8t8HdAxNl+0QP0AruiwX2Zm1gF/Q9XMLENO7mZmGXJyNzPLkJO7mVmGnNzNzDLk5G5mliEndzOzDDm5m5llaPjvkGQDY7Fb0JpZb3nkbmaWISd3M7MMObmbmWXIyd3MLENO7mZmGXJyNzPLkJO7mVmGijxm75OSDkq6t6nsbyTNSLo7vS5u2naVpL2SHpT0srI6bmZmx1Zk5P4pYP0C5VdHxLnpdSuApLOBy4Dnpjb/IumEbnXWzMyKaZncI+IO4McF97cBmIyIxyPiERrPUT2/g/6ZmVkbOrn9wFskvQG4C9gSEYeAVcDupjr7UtlTSBoHxgEqlQr1er2tTszOzrbddinpRZy2jM6Vuv9eqCzL4zjK/rf2710x/YxTu8n9GuC9QKSf24E3Hc8OImICmACoVqtRq9Xa6ki9XqfdtktJL+K0OYN7y2wZnWP71PDfcml6Y63U/fv3rph+xqmtq2Ui4kBEPBERvwI+zq+nXmaANU1VV6cyMzProbaSu6SVTauvAo5cSbMTuEzSyZLOAtYBd3bWRTMzO14t//6U9FmgBpwhaR/wbqAm6Vwa0zLTwJsBIuI+STcA9wNzwBUR8UQ5Xbd+8G19zYZDy+QeEa9boPjaReq/D3hfJ50yM7PO+BuqZmYZcnI3M8uQk7uZWYac3M3MMjT839Yws6dodVXT9LZLetQT6xeP3M3MMuTkbmaWISd3M7MMObmbmWXIyd3MLENO7mZmGXJyNzPLkJO7mVmGnNzNzDLk5G5mliEndzOzDLVM7pI+KemgpHubyk6TdLukh9LPU1O5JH1Y0l5J90h6QZmdNzOzhRUZuX8KWD+vbCuwKyLWAbvSOsDLaTw3dR0wDlzTnW6amdnxaJncI+IO4MfzijcAO9LyDuDSpvLromE3sGLew7TNzKwH2r3lbyUi9qflHwCVtLwK+H5TvX2pbD82FPwAbLM8dHw/94gISXG87SSN05i6oVKpUK/X23r/2dnZttsuJUXjtGV0rvzODLDKsqURg3++/uZjbhtdtbxle//eFdPPOLWb3A9IWhkR+9O0y8FUPgOsaaq3OpU9RURMABMA1Wo1arVaWx2p1+u023YpKRqnzUt85L5ldI7tU0v7GTbTG2st6/j3rph+xqndSyF3ApvS8ibg5qbyN6SrZi4ADjdN35iZWY+0HKJI+ixQA86QtA94N7ANuEHS5cCjwGtT9VuBi4G9wC+AN5bQZzMza6Flco+I1x1j00UL1A3gik47ZWZmnVnak4tLlK+IMcufk7uZHaXVf/7T2y7pUU+sE763jJlZhpzczcwy5ORuZpYhJ3czsww5uZuZZcjJ3cwsQ07uZmYZcnI3M8uQk7uZWYac3M3MMuTkbmaWISd3M7MMObmbmWXIyd3MLEO+5a+ZHZe1W7/EltG5Yz5v17cEHgwdJXdJ08DPgCeAuYioSjoN+BywFpgGXhsRhzrrppmZHY9uTMuMRcS5EVFN61uBXRGxDtiV1s3MrIfKmHPfAOxIyzuAS0t4DzMzW4Qaz7Rus7H0CHAICOBfI2JC0k8iYkXaLuDQkfV5bceBcYBKpXLe5ORkW32YnZ1lZGSk3UPI0tTM4aeUVZbBgcf60Jkh4zgVs1icRlct721nBljZ+WlsbGxP06zJUTo9ofqSiJiR9JvA7ZK+27wxIkLSgv97RMQEMAFQrVajVqu11YF6vU67bXO10ImuLaNzbJ/y+fNWHKdiFovT9MZabzszwPqZnzqalomImfTzIHATcD5wQNJKgPTzYKedNDOz49N2cpf0DEnPPLIM/BFwL7AT2JSqbQJu7rSTZmZ2fDr5+7MC3NSYVudE4DMR8R+SvgncIOly4FHgtZ1308yGxdpjXP8Ovga+l9pO7hHxMPC8Bcp/BFzUSafMzKwzvv2AmVmGnNzNzDLk5G5mliEndzOzDDm5m5llyMndzCxD/p71EFrsOmIzM/DI3cwsSx65DyiPzi1HrT7X/gZr93jkbmaWISd3M7MMObmbmWXIc+594jl1MyuTk7uZDQyfcO0eT8uYmWXII3czGxp+EEhxpSV3SeuBDwEnAJ+IiG1lvVe/eN7cbHB4SudopSR3SScAHwVeCuwDvilpZ0TcX8b7lcXJ2ywfS23UX9bI/Xxgb3oUH5ImgQ1A15P71MxhNjsJm1kHyhz19+svCkVE93cqvRpYHxF/mtZfD7wwIt7SVGccGE+rvw882ObbnQH8sIPuLhWOUzGOUzGOUzFlx+l3IuLMhTb07YRqREwAE53uR9JdEVHtQpey5jgV4zgV4zgV0884lXUp5Aywpml9dSozM7MeKCu5fxNYJ+ksSU8HLgN2lvReZmY2TynTMhExJ+ktwJdpXAr5yYi4r4z3ogtTO0uE41SM41SM41RM3+JUyglVMzPrL99+wMwsQ07uZmYZGtjkLuk0SbdLeij9PPUY9TalOg9J2tRUfp6kKUl7JX1Ykua12yIpJJ1R9rGUqaw4SfqgpO9KukfSTZJW9OqYuknSekkPpuPbusD2kyV9Lm3/hqS1TduuSuUPSnpZ0X0Om27HSNIaSV+TdL+k+yS9tXdHU54yPktp2wmSvi3plq52OCIG8gV8ANialrcC71+gzmnAw+nnqWn51LTtTuACQMBtwMub2q2hcbL3UeCMfh/rIMYJ+CPgxLT8/oX2O+gvGifzvwc8G3g68B3g7Hl1/gL4WFq+DPhcWj471T8ZOCvt54Qi+xymV0kxWgm8INV5JvDfwxyjsuLU1O7twGeAW7rZ54EdudO4XcGOtLwDuHSBOi8Dbo+IH0fEIeB2YL2klcCzImJ3NKJ33bz2VwN/DeRwNrmUOEXEf0bEXGq/m8Z3FYbNk7fBiIhfAkdug9GsOX43Ahelv142AJMR8XhEPALsTfsrss9h0vUYRcT+iPgWQET8DHgAWNWDYylTGZ8lJK0GLgE+0e0OD3Jyr0TE/rT8A6CyQJ1VwPeb1velslVpeX45kjYAMxHxna73uD9KidM8b6Ixqh82xzruBeuk/8wOA6cv0rbIPodJGTF6UpqaeD7wjS72uR/KitM/0Rho/qrbHe7r/dwlfQX4rQU2vat5JSJCUsejbEm/AbyTxpTD0Oh1nOa997uAOeD6bu7X8idpBPgC8LaI+Gm/+zNoJL0COBgReyTVur3/vib3iPjDY22TdEDSyojYn6YPDi5QbQaoNa2vBuqpfPW88hngd2nMeX0nnTdcDXxL0vkR8YMODqVUfYjTkX1vBl4BXJSmbYZNkdtgHKmzT9KJwHLgRy3a5nRrjVJiJOkkGon9+oj4Yjld76ky4vRK4JWSLgZOAZ4l6dMR8Sdd6XG/T1QscgLjgxx9ovADC9Q5DXiExknCU9PyaWnb/BOFFy/QfprhP6FaSpyA9TRu0Xxmv4+xg9icSOPk8Vn8+iTYc+fVuYKjT4LdkJafy9EnwR6mcVKt5T6H6VVSjETj/M0/9fv4BjlO89rW6PIJ1b4HbZFgng7sAh4CvtKUjKo0nux0pN6baJyg2Au8sam8CtxL48z0R0jfxp33Hjkk91LilOp9H7g7vT7W72NtMz4X07ha43vAu1LZe4BXpuVTgM+n470TeHZT23eldg9y9NVWT9nnML+6HSPgJTQuVrin6fPzlMHVsL3K+Cw1be96cvftB8zMMjTIV8uYmVmbnNzNzDLk5G5mliEndzOzDDm5m5llyMndzCxDTu5mZhn6f9IUTHboEp9oAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train error\n",
        "train_result = mean_squared_error(best_enet.predict(x_train), y_train)\n",
        "test_result = mean_squared_error(best_enet.predict(x_test), y_test)\n",
        "\n",
        "print(train_result, test_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gsUrg6q6FZa",
        "outputId": "cf2b0ab2-f671-4499-99e3-41c377cd2bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.047889330800641e-05 9.460190723588174e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positionsytrain = np.where(y_train.values.ravel() > 0,1,-1 )\n",
        "monthlyRetytrain = pd.Series(positionsytrain).shift(1).fillna(0).values * df_ret1\n",
        "monthlyRetytrain = monthlyRetytrain.fillna(0)\n",
        "cumretytrain = np.array(np.cumprod(monthlyRetytrain + 1) - 1)\n",
        "\n",
        "positionsytest = np.where(y_test.values.ravel() > 0,1,-1 )\n",
        "monlthlyRetytest = pd.Series(positionsytest).shift(1).fillna(0).values * df_ret2\n",
        "monlthlyRetytest = monlthlyRetytest.fillna(0)\n",
        "cumretytest = np.array(np.cumprod(monlthlyRetytest + 1) - 1)\n",
        "\n",
        "dates = df.loc[CopyX.index.values].index\n",
        "#dates= dates.reset_index(drop= True)[:x_train.shape[0],]\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(dates, np.concatenate((cumretytrain,cumretytest)) ,'r')\n",
        "pyplot.plot(dates, np.concatenate((cumret,cumret2)),'b')\n",
        "pyplot.title('Equity Curve')\n",
        "pyplot.ylabel('Cumulative Returns')\n",
        "pyplot.xlabel('Date')\n",
        "pyplot.grid()\n",
        "pyplot.show()\n",
        "#dates = df.loc[CopyX.index.values].index # ['Date']\n",
        "#dates= dates.reset_index(drop= True)[x_train.shape[0]:,]\n",
        "#pyplot.plot(dates, cumretytest ,'r')\n",
        "#pyplot.plot(dates, cumret2,'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ry_R8-JSu5eP",
        "outputId": "6f6fce50-2c6a-41ba-fbb7-c6687eda4f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weekly Model"
      ],
      "metadata": {
        "id": "M4mwsqtWzIkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicators\n",
        "\n",
        "def calculate_indicator(df, indicator):\n",
        "    copy_df = df\n",
        "    return_period = 5\n",
        "    if 'TRIX' in indicator:\n",
        "        trix = ta.TRIX(df.Close.values)\n",
        "        copy_df['Trix'] = trix.tolist()\n",
        "    if 'DX' in indicator: \n",
        "        dx = ta.DX(df.High.values, df.Low.values, df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Dx'] = dx.tolist()\n",
        "    if 'SMA' in indicator: \n",
        "        sma = ta.SMA(df.Close.values)\n",
        "        copy_df['Sma'] = sma.tolist()\n",
        "    if 'CCI' in indicator: \n",
        "        cci = ta.CCI(df.High.values, df.Low.values, df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Cci'] = cci.tolist()\n",
        "    if 'ROC' in indicator: \n",
        "        roc = ta.ROC(df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Roc'] = roc.tolist()\n",
        "    if 'CMO' in indicator: \n",
        "        cmo = ta.CMO(df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Cmo'] = cmo.tolist()\n",
        "    if 'ATR' in indicator: \n",
        "        atr = ta.ATR(df.High.values, df.Low.values, df.Close.values, timeperiod = return_period)\n",
        "        copy_df['Atr'] = atr.tolist()\n",
        "    return copy_df"
      ],
      "metadata": {
        "id": "0Ux4Zq0N-7hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define monthly return period\n",
        "return_period = 5\n",
        "\n",
        "# Calculate lags from return period \n",
        "def calculate_lags(df):\n",
        "    temp = pd.DataFrame(np.log(df[\"Adj Close\"]).diff(return_period).shift(-return_period))\n",
        "    return temp\n",
        "\n",
        "appended_data = []\n",
        "for stock in df_list:\n",
        "    temp = calculate_lags(stock)\n",
        "    appended_data.append(temp)\n",
        "\n",
        "dataset = pd.DataFrame()\n",
        "dataset = pd.concat(appended_data, axis=1)\n",
        "col_names = [\"TSLA\", \"GE\", \"F\", \"VUG\", \"SPY\", \"AGG\", \"GSPC\", \"DJI\", \"IXIC\", \"VOO_Predicted\"]\n",
        "dataset.columns = col_names\n",
        "\n",
        "# calculate lags for VOO\n",
        "voo_lags = pd.concat([np.log(voo_data[\"Adj Close\"]).diff(i) for i in [return_period, return_period*3, return_period*6, return_period*10]], axis=1)\n",
        "voo_lags.columns = [\"VOO_\" + str(return_period), \"VOO_\" + str(return_period*3), \"VOO_\" + str(return_period*6), \"VOO_\" + str(return_period*10)]\n",
        "\n",
        "# Compose complete dataset\n",
        "complete_data = pd.concat([dataset, voo_lags], axis=1).dropna().iloc[::return_period, :]\n",
        "\n",
        "# Extract X and Y variables \n",
        "CopyX = complete_data[[\"VOO_Predicted\"]].copy()\n",
        "Y = complete_data[[\"VOO_Predicted\"]].reset_index(drop= True)\n",
        "X = complete_data.loc[:, complete_data.columns != 'VOO_Predicted']"
      ],
      "metadata": {
        "id": "lelyJG3N_SBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voo = calculate_indicator(voo_data, ['TRIX','DX','CMO','ROC','CCI','ATR'])\n",
        "X = X.join(voo.iloc[:,-6:])\n",
        "X = X.fillna(X.mean())\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=0)"
      ],
      "metadata": {
        "id": "0oNNRIDD_amv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "std_slc = StandardScaler()\n",
        "pca = PCA()\n",
        "elasticnet = ElasticNet()\n",
        "\n",
        "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
        "                           ('pca', pca),\n",
        "                           ('elasticnet', elasticnet)])\n",
        "\n",
        "\n",
        "n_components = list(range(1,X.shape[1]+1,1))\n",
        "normalize = [True, False]\n",
        "selection = ['cyclic', 'random']\n",
        "l1_ratios = [0.1, 0.2, 0.5]\n",
        "parameters = dict(pca__n_components=n_components,\n",
        "                      elasticnet__normalize=normalize,\n",
        "                      elasticnet__selection=selection)"
      ],
      "metadata": {
        "id": "Mrxq4lOR_ji3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "X_train = scaler.transform(x_train)\n",
        "X_test = scaler.transform(x_test)\n",
        "\n",
        "pca = PCA(n_components=1)\n",
        "pca.fit(x_train)\n",
        "X_train = pca.transform(x_train)\n",
        "X_test = pca.transform(x_test)\n",
        "\n",
        "\n",
        "best_enet = ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=True, l1_ratio=0.0,\n",
        "      max_iter=10, normalize=True, positive=False, precompute=False,\n",
        "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
        "best_enet.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q82R5hz_qSs",
        "outputId": "e7459ca9-621f-4dd5-8c81-9d2b9ee4a868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), ElasticNet())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to original_alpha * np.sqrt(n_samples) if l1_ratio is 1, and to original_alpha * n_samples if l1_ratio is 0. For other values of l1_ratio, no analytic formula is available.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e-03, tolerance: 1.790e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=0.0001, l1_ratio=0.0, max_iter=10, normalize=True)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_y = y_test.values.ravel()\n",
        "pred_y = best_enet.predict(x_test)\n",
        "\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(true_y, label='true_y')\n",
        "pyplot.plot(pred_y, label='pred_y')\n",
        "pyplot.figsize=(10,20)\n",
        "pyplot.xlabel('Time')\n",
        "pyplot.ylabel('Return Range')\n",
        "pyplot.title('Train VS Test')\n",
        "pyplot.grid()\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "k8XjcpkR_vax",
        "outputId": "4e0c5dc8-4686-420f-916a-a3060052c378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ret = voo_data.iloc[:]['Adj Close'].pct_change(periods=1).fillna(0)\n",
        "df_ret1 = df_ret.reset_index(drop= True)[:x_train.shape[0],]\n",
        "df_ret2 = df_ret.reset_index(drop= True)[:x_test.shape[0],]\n",
        "\n",
        "positions = np.where(best_enet.predict(x_train)> 0,1,-1 ) \n",
        "montly_Ret = pd.Series(positions).shift(1).fillna(0).values * df_ret1\n",
        "montly_Ret = montly_Ret.fillna(0)\n",
        "cumret = np.array(np.cumprod(montly_Ret + 1) - 1)\n",
        "\n",
        "rho, pval = spearmanr(y_test,best_enet.predict(x_test)) \n",
        "cagr = (1 + cumret[-1]) ** ((253/5) / len(cumret)) - 1\n",
        "maxDD, maxDDD = fAux.calculateMaxDD(cumret)\n",
        "ratio = ((253/5) ** (1.0/2.0)) * np.mean(montly_Ret) / np.std(montly_Ret)\n",
        "print (('In-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6} Rho={:0.6} PVal={:0.6}\\n'\\\n",
        "    ).format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD, rho, pval))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54PJsUr4_2t-",
        "outputId": "9e34285a-773b-42bf-a1e3-6b6a00f21be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-sample: CAGR=0.0346898 Sharpe ratio=0.625494 maxDD=-0.0638602 maxDDD=69 Calmar ratio=0.543215 Rho=0.992016 PVal=3.12694e-241\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positions2 = np.where(best_enet.predict(x_test)> 0,1,-1 )\n",
        "monthly_ret2 = pd.Series(positions2).shift(1).fillna(0).values * df_ret2\n",
        "monthly_ret2 = monthly_ret2.fillna(0)\n",
        "cumret2 = np.array(np.cumprod(monthly_ret2 + 1) - 1)\n",
        "\n",
        "rho, pval = spearmanr(y_test,best_enet.predict(x_test)) \n",
        "\n",
        "cagr = (1 + cumret2[-1]) ** ((253/5) / len(cumret2)) - 1\n",
        "maxDD, maxDDD = fAux.calculateMaxDD(cumret2)\n",
        "ratio = ((253/5) ** (1.0/2.0)) * np.mean(monthly_ret2) / np.std(monthly_ret2)\n",
        "print (('Out-of-sample: CAGR={:0.6} Sharpe ratio={:0.6} maxDD={:0.6} maxDDD={:d} Calmar ratio={:0.6}  Rho={:0.6} PVal={:0.6}\\n'\\\n",
        ").format(cagr, ratio, maxDD, maxDDD.astype(int), -cagr/maxDD, rho, pval))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_Fm6NBWABv_",
        "outputId": "63f9b1f7-ae3e-4c68-fbd3-270adcbbcf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-sample: CAGR=0.00298742 Sharpe ratio=0.0807233 maxDD=-0.161198 maxDDD=182 Calmar ratio=0.0185327  Rho=0.992016 PVal=3.12694e-241\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_close=voo_data.iloc[:]['Adj Close'].reset_index(drop= True)[(x_train.shape[0]):,]\n",
        "detrended_close = detrendPrice.detrendPrice(new_close)\n",
        "detrended_ret1 = detrended_close.pct_change(periods=1).fillna(0)\n",
        "detrended_syst_rets = detrended_ret1 * pd.Series(positions2).shift(1).fillna(0)\n",
        "WhiteRealityCheckFor1.bootstrap(detrended_syst_rets)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "Q5ygXQObAIIi",
        "outputId": "de0d7682-052c-49ff-b191-eedf83c67a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average return 0.000203\n",
            "[-0.00085463  0.00083714]\n",
            "Do not reject Ho = The population distribution of rule returns has an expected value of zero or less (because p_value is not small enough)\n",
            "p_value:\n",
            "0.3254\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train error\n",
        "train_result = mean_squared_error(best_enet.predict(x_train), y_train)\n",
        "test_result = mean_squared_error(best_enet.predict(x_test), y_test)\n",
        "\n",
        "print(train_result, test_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqeb3IQnAJqf",
        "outputId": "f9277457-a0b6-49aa-d249-352a3d7af5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.039159413441891e-06 7.1906130521546984e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positionsytrain = np.where(y_train.values.ravel() > 0,1,-1 )\n",
        "monthlyRetytrain = pd.Series(positionsytrain).shift(1).fillna(0).values * df_ret1\n",
        "monthlyRetytrain = monthlyRetytrain.fillna(0)\n",
        "cumretytrain = np.array(np.cumprod(monthlyRetytrain + 1) - 1)\n",
        "\n",
        "positionsytest = np.where(y_test.values.ravel() > 0,1,-1 )\n",
        "monlthlyRetytest = pd.Series(positionsytest).shift(1).fillna(0).values * df_ret2\n",
        "monlthlyRetytest = monlthlyRetytest.fillna(0)\n",
        "cumretytest = np.array(np.cumprod(monlthlyRetytest + 1) - 1)\n",
        "\n",
        "dates = df.loc[CopyX.index.values].index\n",
        "#dates= dates.reset_index(drop= True)[:x_train.shape[0],]\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(dates, np.concatenate((cumretytrain,cumretytest)) ,'r')\n",
        "pyplot.plot(dates, np.concatenate((cumret,cumret2)),'b')\n",
        "pyplot.title('Equity Curve')\n",
        "pyplot.ylabel('Cumulative Returns')\n",
        "pyplot.xlabel('Date')\n",
        "pyplot.grid()\n",
        "pyplot.show()\n",
        "#dates = df.loc[CopyX.index.values].index # ['Date']\n",
        "#dates= dates.reset_index(drop= True)[x_train.shape[0]:,]\n",
        "#pyplot.plot(dates, cumretytest ,'r')\n",
        "#pyplot.plot(dates, cumret2,'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "af6xoDLbAMol",
        "outputId": "82b78d1b-38ba-4490-b0a7-4354341de748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "56fecb26f35ad399d6fb3c223fb988289bbfbf62a99aeb18ada3481a4baa4e74"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}